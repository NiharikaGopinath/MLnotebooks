{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "To use textual data for predictive modelling, the text must be parsed to remove a certain words. This is called Tokenisation.\n",
    "These tokens are then encoded to integers or floats to be used as inputs to the ML model. This is called Vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0]]\n",
      "{'simon': 15, 'baker': 4, 'and': 2, 'gabriel': 6, 'macht': 10, 'are': 3, 'amazing': 1, 'actors': 0, 'suits': 17, 'mentalist': 11, 'the': 18, 'best': 5, 'shows': 14, 'have': 8, 'seen': 13, 'harvey': 7, 'specter': 16, 'patrick': 12, 'jane': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = [\"Simon Baker and Gabriel Macht are amazing actors.\", \"Suits and Mentalist are the best shows I have seen\", \"Harvey Specter and Patrick Jane\"]\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(docs)\n",
    "print(X.todense())\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DictVectorizer\n",
    "\n",
    "It converts mapping to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 2. 1. 0. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 1. 2. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "docs = [{\"Harvey Specter\": 1, \"is\": 1, \"awesome\": 2}, {\"Life\": 1, \"is\": 1, \"like \": 2, \"this\": 3, \"and\": 1, \"I\": 2, \"like it\": 3}]\n",
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(docs)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf Vectorizer\n",
    "\n",
    "It is a solution for repeated words in a text, such that the repeated words get less weightage. Idf refers to Inverse Document Frequency and Tf refers to term frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.76749457 0.45329466 0.45329466 0.         0.        ]\n",
      " [0.         0.         0.45329466 0.45329466 0.76749457 0.        ]\n",
      " [0.6088451  0.         0.35959372 0.35959372 0.         0.6088451 ]]\n",
      "{'mayur': 3, 'is': 2, 'guitarist': 1, 'musician': 4, 'also': 0, 'programmer': 5}\n",
      "[[0 1 1 1 0 0]\n",
      " [0 0 1 1 1 0]\n",
      " [1 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "cv_vectorizer = CountVectorizer()\n",
    "docs = [\"Mayur is a Guitarist\", \"Mayur is Musician\", \"Mayur is also a programmer\"]\n",
    "X_idf = tfidf_vectorizer.fit_transform(docs)\n",
    "X_cv = cv_vectorizer.fit_transform(docs)\n",
    "print(X_idf.todense())\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(X_cv.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
